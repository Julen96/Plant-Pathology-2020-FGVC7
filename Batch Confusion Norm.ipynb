{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Confusion Norm Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras import models, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, Dropout, Multiply\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.applications.resnet import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras import losses\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_augmented(directory):\n",
    "    \n",
    "    # This function loads the augmented images and the augmented csv file\n",
    "    df_train = pd.read_csv(directory + 'augmented.csv')\n",
    "    train_image = []\n",
    "    for name in df_train['image_id']:\n",
    "        name = name.lower()\n",
    "        path = directory + 'images_resized_augmented/' + name + '.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        train_image.append(img)\n",
    "    train_image_array = np.array(train_image)\n",
    "    \n",
    "    return  train_image_array, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/'\n",
    "x_train, df_train = load_images_augmented(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train = x_train / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = df_train[['healthy', 'multiple_diseases', 'rust', 'scab']].to_numpy()\n",
    "\n",
    "x_train_original, y_train_original = shuffle(x_train, y_train)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_original, y_train_original, test_size = 0.2, random_state = 2020)\n",
    "\n",
    "print('Size of x_train: ', x_train.shape)\n",
    "print('Size of x_val: ', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Confusion Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_plot(history):\n",
    "\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, x_test, y_test):\n",
    "    score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASSP(output, act_name): # TODO: Check if it is well built. Not like in paper. Maybe different image size?\n",
    "    ASSP = Conv2D(filters = 2048, kernel_size = (1,1))(output)\n",
    "    ASSP = Conv2D(filters = 2048, kernel_size = (3,3), dilation_rate = 2)(ASSP)\n",
    "#     ASSP = Conv2D(filters = 2048, kernel_size = (3,3), dilation_rate = 4)(ASSP)\n",
    "    # ASSP = Conv2D(filters = 2048, kernel_size = (3,3), dilation_rate = 6)(ASSP)\n",
    "    # ASSP = Conv2D(filters = 2048, kernel_size = (3,3), dilation_rate = 7)(ASSP)\n",
    "\n",
    "    ASSP = Activation(act_name)(ASSP)\n",
    "    \n",
    "    return ASSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bcn_loss(y_pred):\n",
    "\n",
    "    \n",
    "    matrix = K.dot(K.transpose(y_pred), y_pred)\n",
    "    eigenvalues, eigenvectors = tf.linalg.eigh(matrix)\n",
    "    bcn_loss = K.sum(eigenvalues) \n",
    "    \n",
    "    print(eigenvalues)\n",
    "    print(type(eigenvalues))\n",
    "    print(type(y_pred))\n",
    "    print('y_pred shape: ', y_pred.shape)\n",
    "    print('yPred.transpose shape: ', K.transpose(y_pred).shape)\n",
    "    print('matrix shape: ', matrix.shape)\n",
    "    print('eigenvalues shape: ', eigenvalues.shape)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return bcn_loss\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    categorical_crossentropy = losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    BCN_loss = compute_bcn_loss(y_pred)\n",
    "    \n",
    "    loss_total = categorical_crossentropy + BCN_loss\n",
    "    \n",
    "    return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "model_resnet = ResNet50(include_top = False, weights = 'imagenet', input_shape = input_shape)\n",
    "inputs = Input(shape = (224, 224, 3))\n",
    "out = model_resnet(inputs)\n",
    "features = ASSP(out, 'relu')\n",
    "attention = ASSP(out, 'sigmoid')\n",
    "tensor_total = Multiply()([features, attention])\n",
    "tensor_total_flat = Flatten()(tensor_total)\n",
    "tensor_total_flat = Dense(256, activation = 'relu')(tensor_total_flat) # TODO: Check if it should be relu or another\n",
    "tensor_total_flat = Dense(4, activation = 'softmax')(tensor_total_flat)\n",
    "\n",
    "model = Model(inputs=inputs, outputs= tensor_total_flat)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = custom_loss, metrics = ['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train[:120], y_train[:120], batch_size = 2, epochs = 3, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    \"\"\" Saves the model as a Json file\"\"\"\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open( str(name) + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(name + \".h5\")\n",
    "    print(\"Saved model to disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, name = 'BCN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
